{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import distutils.dir_util\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def write_json(data, fname):\n",
    "    def _conv(o):\n",
    "        if isinstance(o, (np.int64, np.int32)):\n",
    "            return int(o)\n",
    "        raise TypeError\n",
    "\n",
    "    parent = os.path.dirname(fname)\n",
    "    distutils.dir_util.mkpath(\"./arena_data/\" + parent)\n",
    "    with io.open(\"./arena_data/\" + fname, \"w\", encoding=\"utf-8\") as f:\n",
    "        json_str = json.dumps(data, ensure_ascii=False, default=_conv)\n",
    "        f.write(json_str)\n",
    "\n",
    "\n",
    "def load_json(fname):\n",
    "    with open(fname, encoding=\"utf-8\") as f:\n",
    "        json_obj = json.load(f)\n",
    "\n",
    "    return json_obj\n",
    "\n",
    "\n",
    "def debug_json(r):\n",
    "    print(json.dumps(r, ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def json_to_dataframe(json_data):\n",
    "    dataframe_dict = {'id': [], 'plylst_title': [], 'tags': [], 'songs': [], 'like_cnt': [], 'updt_date': []}\n",
    "\n",
    "    for data in tqdm(json_data):\n",
    "        dataframe_dict['id'].append(data['id'])\n",
    "        dataframe_dict['plylst_title'].append(data['plylst_title'])\n",
    "        dataframe_dict['tags'].append(data['tags'])\n",
    "        dataframe_dict['songs'].append(data['songs'])\n",
    "        dataframe_dict['like_cnt'].append(data['like_cnt'])\n",
    "        dataframe_dict['updt_date'].append(data['updt_date'])\n",
    "    \n",
    "    dataframe = pd.DataFrame(dataframe_dict)\n",
    "    dataframe['updt_date'] = pd.to_datetime(dataframe.updt_date)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def get_unique_items(dataframe, column, list_type=True):\n",
    "    unique_items = set()\n",
    "    if list_type:\n",
    "        for c in tqdm(dataframe[column]):\n",
    "            unique_items |= set(c)\n",
    "    else:\n",
    "        assert len(dataframe[column].unique()) == len(dataframe[column])\n",
    "        unique_items = dataframe[column].unique()\n",
    "    \n",
    "    return unique_items\n",
    "\n",
    "\n",
    "def make_item_index_dictionary(items):\n",
    "    item2idx = {item:idx for idx, item in enumerate(items)}\n",
    "    idx2item = {idx:item for item, idx in item2idx.items()}\n",
    "    return item2idx, idx2item\n",
    "\n",
    "\n",
    "def dataframe_to_matrix(dataframe, item='tags', playlist2idx=None, item2idx=None):\n",
    "    assert item in ['tags', 'songs']\n",
    "\n",
    "    matrix_shape = (len(playlist2idx), len(item2idx))\n",
    "\n",
    "    if 'plylst_id' not in dataframe.columns:\n",
    "        dataframe['plylst_id'] = dataframe.id.map(playlist2idx)\n",
    "\n",
    "    column_name = '{}_id'.format(item)\n",
    "    if column_name not in dataframe.columns:\n",
    "        dataframe[column_name] = dataframe[item].apply(lambda items: [item2idx[item] for item in items])\n",
    "\n",
    "    rows = list()\n",
    "    cols = list()\n",
    "    data = list()\n",
    "\n",
    "    for r, cs in tqdm(zip(dataframe.plylst_id, dataframe[column_name])):\n",
    "        for c in cs:\n",
    "            rows.append(r)\n",
    "            cols.append(c)\n",
    "    \n",
    "    rows = np.array(rows)\n",
    "    cols = np.array(cols)\n",
    "    data = np.ones(rows.shape[0])\n",
    "\n",
    "    return sp.csr_matrix((data, (rows, cols)), shape=matrix_shape)\n",
    "\n",
    "def transform_sparse_matrix_tfidf(train_test, train, test):\n",
    "    transformer = TfidfTransformer(smooth_idf=True)\n",
    "    transformer.fit(train_test)\n",
    "    tfidf_train = transformer.transform(train)\n",
    "    tfidf_test = transformer.transform(test)\n",
    "\n",
    "    return transformer, tfidf_train, tfidf_test\n",
    "\n",
    "\n",
    "def _calculate_cosine_similarity(A, B):\n",
    "    return cosine_similarity(A, B, dense_output=False)\n",
    "\n",
    "### fint neighbors of test from train\n",
    "def find_neigbors(tag_train, tag_test, song_train, song_test, k=5):\n",
    "    train = sp.hstack([tag_train * 0.15, song_train * 0.85])\n",
    "    test = sp.hstack([tag_test * 0.15, song_test * 0.85])\n",
    "\n",
    "    similarity = _calculate_cosine_similarity(test, train)\n",
    "    neighbors = list()\n",
    "    for rid in tqdm(range(similarity.shape[0])):\n",
    "        neighbors.append(np.argsort(similarity[rid, :].toarray()[0])[::-1][:k])\n",
    "    \n",
    "    neighbors = np.array(neighbors)\n",
    "    return similarity, neighbors\n",
    "\n",
    "def recommend_items(id, train, test, neighbors, idx2item, n):\n",
    "    counter = 0\n",
    "    items = list()\n",
    "    for item_id in train[neighbors, :].toarray().sum(axis=0).argsort()[::-1]:\n",
    "        if item_id not in test[id, :].nonzero()[1]:\n",
    "            item = idx2item[item_id]\n",
    "            items.append(item)\n",
    "            counter += 1\n",
    "        if counter == n:\n",
    "            break\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnnModel:\n",
    "    def __init__(self, k=10):\n",
    "        # Model Parameters\n",
    "        self.k = k\n",
    "\n",
    "        # Item Dictionaries\n",
    "        self.idx2tag = None\n",
    "        self.idx2song = None\n",
    "        self.idx2playlist = None\n",
    "\n",
    "\n",
    "    def _preprocess_data(self, train, test, tfidf=True):\n",
    "        unique_tags = get_unique_items(pd.concat([train, test], ignore_index=True, copy=False), 'tags', list_type=True)\n",
    "        unique_songs = get_unique_items(pd.concat([train, test], ignore_index=True, copy=False), 'songs', list_type=True)\n",
    "        unique_playlists_train = get_unique_items(train, 'id', list_type=False)\n",
    "        unique_playlists_test = get_unique_items(test, 'id', list_type=False)\n",
    "\n",
    "        tag2idx, idx2tag = make_item_index_dictionary(unique_tags)\n",
    "        song2idx, idx2song = make_item_index_dictionary(unique_songs)\n",
    "\n",
    "        playlist2idx_train, idx2playlist_train = make_item_index_dictionary(unique_playlists_train)\n",
    "        playlist2idx_test, idx2playlist_test = make_item_index_dictionary(unique_playlists_test)\n",
    "\n",
    "        N_TRAIN = len(playlist2idx_train)\n",
    "\n",
    "        playlist2idx = {playlist:idx for playlist, idx in playlist2idx_train.items()}\n",
    "        for playlist, idx in playlist2idx_test.items():\n",
    "            playlist2idx[playlist] = (idx + N_TRAIN)\n",
    "        idx2playlist = {idx:playlist for playlist, idx in playlist2idx.items()}\n",
    "\n",
    "        assert len(playlist2idx_train) + len(playlist2idx_test) == len(playlist2idx)\n",
    "\n",
    "        self.idx2tag = idx2tag\n",
    "        self.idx2song = idx2song\n",
    "        self.idx2playlist = (idx2playlist_train,  idx2playlist_test)\n",
    "\n",
    "        PT_train = dataframe_to_matrix(train, item='tags', playlist2idx=playlist2idx_train, item2idx=tag2idx)\n",
    "        PT_test = dataframe_to_matrix(test, item='tags', playlist2idx=playlist2idx_test, item2idx=tag2idx)\n",
    "        PT = dataframe_to_matrix(pd.concat([train, test], ignore_index=True, copy=False), item='tags', playlist2idx=playlist2idx, item2idx=tag2idx)\n",
    "\n",
    "        PS_train = dataframe_to_matrix(train, item='songs', playlist2idx=playlist2idx_train, item2idx=song2idx)\n",
    "        PS_test = dataframe_to_matrix(test, item='songs', playlist2idx=playlist2idx_test, item2idx=song2idx)\n",
    "        PS = dataframe_to_matrix(pd.concat([train, test], ignore_index=True, copy=False), item='songs', playlist2idx=playlist2idx, item2idx=song2idx)\n",
    "\n",
    "        if tfidf:\n",
    "            _, PT_tfidf_train, PT_tfidf_test = transform_sparse_matrix_tfidf(PT, PT_train, PT_test)\n",
    "            _, PS_tfidf_train, PS_tfidf_test = transform_sparse_matrix_tfidf(PS, PS_train, PS_test)\n",
    "\n",
    "            return PT_tfidf_train, PT_tfidf_test, PS_tfidf_train, PS_tfidf_test\n",
    "\n",
    "        return PT_train, PT_test, PS_train, PS_test\n",
    "\n",
    "\n",
    "    def recommend(self, train, test):\n",
    "        print(\"Preprocessing data... > to sparse matrix\")\n",
    "        PT_train, PT_test, PS_train, PS_test = self._preprocess_data(train, test)\n",
    "        \n",
    "        print(\"Prepare for recommendations... > find {} neighbors\".format(self.k))\n",
    "        _, neighbors = find_neigbors(PT_train, PT_test, PS_train, PS_test, self.k)\n",
    "\n",
    "        print(\"Recommend items...\")\n",
    "        recommendations = list()\n",
    "\n",
    "        assert PT_test.shape[0] == PS_test.shape[0]\n",
    "        N_TEST = PT_test.shape[0]\n",
    "\n",
    "        for rid in tqdm(range(N_TEST)):\n",
    "            playlist = self.idx2playlist[1][rid]\n",
    "            rid_neighbors = neighbors[rid, :]\n",
    "\n",
    "            tags = recommend_items(rid, PT_train, PT_test, rid_neighbors, self.idx2tag, 10)\n",
    "            songs = recommend_items(rid, PS_train, PS_test, rid_neighbors, self.idx2song, 100)\n",
    "\n",
    "            recommendations.append({\n",
    "                \"id\": playlist,\n",
    "                \"songs\": songs,\n",
    "                \"tags\": tags,\n",
    "            })\n",
    "\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaylistContinuation:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def _generate_answers(self, train, test):\n",
    "        print(\"Preprocessing data... > to dataframe\")\n",
    "        train = json_to_dataframe(train)\n",
    "        test = json_to_dataframe(test)\n",
    "\n",
    "        self.model = KnnModel(k=1000)\n",
    "        return self.model.recommend(train, test)\n",
    "\n",
    "\n",
    "    def run(self, train_fname, question_fname):\n",
    "        print(\"Loading train file...\")\n",
    "        train_data = load_json(train_fname)\n",
    "\n",
    "        print(\"Loading question file...\")\n",
    "        test_data = load_json(question_fname)\n",
    "\n",
    "        answers = self._generate_answers(train_data, test_data)\n",
    "    \n",
    "        print(\"Writing answers...\")\n",
    "        write_json(answers, \"results/results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelKNNTFIDF:\n",
    "    def _generate_answers(self, train, questions):\n",
    "        print(\"Preprocessing data... > to dataframe\")\n",
    "        train = json_to_dataframe(train)\n",
    "        test = json_to_dataframe(questions)\n",
    "\n",
    "        N_TRAIN = len(train)\n",
    "        N_TEST = len(test)\n",
    "\n",
    "        print(\"Preprocessing data... > to sparse matrix\")\n",
    "        unique_tags = get_unique_items(pd.concat([train, test], ignore_index=True, copy=False), 'tags', list_type=True)\n",
    "        unique_songs = get_unique_items(pd.concat([train, test], ignore_index=True, copy=False), 'songs', list_type=True)\n",
    "        unique_playlists_train = get_unique_items(train, 'id', list_type=False)\n",
    "        unique_playlists_test = get_unique_items(test, 'id', list_type=False)\n",
    "\n",
    "        tag2idx, idx2tag = make_item_index_dictionary(unique_tags)\n",
    "        song2idx, idx2song = make_item_index_dictionary(unique_songs)\n",
    "\n",
    "        playlist2idx_train, idx2playlist_train = make_item_index_dictionary(unique_playlists_train)\n",
    "        playlist2idx_test, idx2playlist_test = make_item_index_dictionary(unique_playlists_test)\n",
    "\n",
    "        playlist2idx = {playlist:idx for playlist, idx in playlist2idx_train.items()}\n",
    "        for playlist, idx in playlist2idx_test.items():\n",
    "            playlist2idx[playlist] = (idx + N_TRAIN)\n",
    "        idx2playlist = {idx:playlist for playlist, idx in playlist2idx.items()}\n",
    "\n",
    "        assert len(playlist2idx_train) + len(playlist2idx_test) == len(playlist2idx)\n",
    "\n",
    "        PT_train = dataframe_to_matrix(train, item='tags', playlist2idx=playlist2idx_train, item2idx=tag2idx)\n",
    "        PT_test = dataframe_to_matrix(test, item='tags', playlist2idx=playlist2idx_test, item2idx=tag2idx)\n",
    "        PT = dataframe_to_matrix(pd.concat([train, test], ignore_index=True, copy=False), item='tags', playlist2idx=playlist2idx, item2idx=tag2idx)\n",
    "\n",
    "        PS_train = dataframe_to_matrix(train, item='songs', playlist2idx=playlist2idx_train, item2idx=song2idx)\n",
    "        PS_test = dataframe_to_matrix(test, item='songs', playlist2idx=playlist2idx_test, item2idx=song2idx)\n",
    "        PS = dataframe_to_matrix(pd.concat([train, test], ignore_index=True, copy=False), item='songs', playlist2idx=playlist2idx, item2idx=song2idx)\n",
    "\n",
    "        _, PT_tfidf_train, PT_tfidf_test = transform_sparse_matrix_tfidf(PT, PT_train, PT_test)\n",
    "        _, PS_tfidf_train, PS_tfidf_test = transform_sparse_matrix_tfidf(PS, PS_train, PS_test)\n",
    "        \n",
    "        k = 100\n",
    "        print(\"Prepare for recommendations... > find {} neighbors\".format(k))\n",
    "        _, neighbors = find_neigbors(PT_tfidf_train, PT_tfidf_test, PS_tfidf_train, PS_tfidf_test, k)\n",
    "\n",
    "        answers = list()\n",
    "        for rid in tqdm(range(N_TEST)):\n",
    "            playlist = idx2playlist_test[rid]\n",
    "            rid_neighbors = neighbors[rid, :]\n",
    "\n",
    "            tags = recommend_items(rid, PT_tfidf_train, PT_tfidf_test, rid_neighbors, idx2tag, 10)\n",
    "            songs = recommend_items(rid, PS_tfidf_train, PS_tfidf_test, rid_neighbors, idx2song, 100)\n",
    "\n",
    "            answers.append({\n",
    "                \"id\": playlist,\n",
    "                \"songs\": songs,\n",
    "                \"tags\": tags,\n",
    "            })\n",
    "\n",
    "        return answers\n",
    "\n",
    "    def run(self, train_fname, question_fname):\n",
    "        print(\"Loading train file...\")\n",
    "        train_data = load_json(train_fname)\n",
    "\n",
    "        print(\"Loading question file...\")\n",
    "        test_data = load_json(question_fname)\n",
    "\n",
    "        answers = self._generate_answers(train_data, test_data)\n",
    "\n",
    "        print(\"Writing answers...\")\n",
    "        write_json(answers, \"results/results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import fire\n",
    "import numpy as np\n",
    "\n",
    "class ArenaEvaluator:\n",
    "    def _idcg(self, l):\n",
    "        return sum((1.0 / np.log(i + 2) for i in range(l)))\n",
    "\n",
    "    def __init__(self):\n",
    "        self._idcgs = [self._idcg(i) for i in range(101)]\n",
    "\n",
    "    def _ndcg(self, gt, rec):\n",
    "        dcg = 0.0\n",
    "        for i, r in enumerate(rec):\n",
    "            if r in gt:\n",
    "                dcg += 1.0 / np.log(i + 2)\n",
    "\n",
    "        return dcg / self._idcgs[len(gt)]\n",
    "\n",
    "    def _eval(self, gt_fname, rec_fname):\n",
    "        gt_playlists = load_json(gt_fname)\n",
    "        gt_dict = {g[\"id\"]: g for g in gt_playlists}\n",
    "        rec_playlists = load_json(rec_fname)\n",
    "\n",
    "        gt_ids = set([g[\"id\"] for g in gt_playlists])\n",
    "        rec_ids = set([r[\"id\"] for r in rec_playlists])\n",
    "\n",
    "        if gt_ids != rec_ids:\n",
    "            raise Exception(\"결과의 플레이리스트 수가 올바르지 않습니다.\")\n",
    "\n",
    "        rec_song_counts = [len(p[\"songs\"]) for p in rec_playlists]\n",
    "        rec_tag_counts = [len(p[\"tags\"]) for p in rec_playlists]\n",
    "\n",
    "        if set(rec_song_counts) != set([100]):\n",
    "            raise Exception(\"추천 곡 결과의 개수가 맞지 않습니다.\")\n",
    "\n",
    "        if set(rec_tag_counts) != set([10]):\n",
    "            raise Exception(\"추천 태그 결과의 개수가 맞지 않습니다.\")\n",
    "\n",
    "        rec_unique_song_counts = [len(set(p[\"songs\"])) for p in rec_playlists]\n",
    "        rec_unique_tag_counts = [len(set(p[\"tags\"])) for p in rec_playlists]\n",
    "\n",
    "        if set(rec_unique_song_counts) != set([100]):\n",
    "            raise Exception(\"한 플레이리스트에 중복된 곡 추천은 허용되지 않습니다.\")\n",
    "\n",
    "        if set(rec_unique_tag_counts) != set([10]):\n",
    "            raise Exception(\"한 플레이리스트에 중복된 태그 추천은 허용되지 않습니다.\")\n",
    "\n",
    "        music_ndcg = 0.0\n",
    "        tag_ndcg = 0.0\n",
    "\n",
    "        for rec in rec_playlists:\n",
    "            gt = gt_dict[rec[\"id\"]]\n",
    "            music_ndcg += self._ndcg(gt[\"songs\"], rec[\"songs\"][:100])\n",
    "            tag_ndcg += self._ndcg(gt[\"tags\"], rec[\"tags\"][:10])\n",
    "\n",
    "        music_ndcg = music_ndcg / len(rec_playlists)\n",
    "        tag_ndcg = tag_ndcg / len(rec_playlists)\n",
    "        score = music_ndcg * 0.85 + tag_ndcg * 0.15\n",
    "\n",
    "        return music_ndcg, tag_ndcg, score\n",
    "\n",
    "    def evaluate(self, gt_fname, rec_fname):\n",
    "        try:\n",
    "            music_ndcg, tag_ndcg, score = self._eval(gt_fname, rec_fname)\n",
    "            print(f\"Music nDCG: {music_ndcg:.6}\")\n",
    "            print(f\"Tag nDCG: {tag_ndcg:.6}\")\n",
    "            print(f\"Score: {score:.6}\")\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # k-neighbor = 10\n",
    "\n",
    "# model = ModelKNNTFIDF()\n",
    "# model.run(train_fname='../arena_data/orig/train.json', question_fname='../arena_data/questions/val.json')\n",
    "\n",
    "# evaluator = ArenaEvaluator()\n",
    "# evaluator.evaluate(gt_fname='../arena_data/answers/val.json', rec_fname='./arena_data/results/results.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Music nDCG: 0.10744\n",
    "Tag nDCG: 0.323821\n",
    "Score: 0.139897"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # k-neighbor = 100\n",
    "\n",
    "# model = ModelKNNTFIDF()\n",
    "# model.run(train_fname='../arena_data/orig/train.json', question_fname='../arena_data/questions/val.json')\n",
    "\n",
    "# evaluator = ArenaEvaluator()\n",
    "# evaluator.evaluate(gt_fname='../arena_data/answers/val.json', rec_fname='./arena_data/results/results.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Music nDCG: 0.111104\n",
    "Tag nDCG: 0.39274\n",
    "Score: 0.15335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loading train file...\n100%|██████████| 9205/9205 [00:00<00:00, 605349.23it/s]\n100%|██████████| 2302/2302 [00:00<00:00, 761998.88it/s]\n100%|██████████| 11507/11507 [00:00<00:00, 771715.45it/s]\n100%|██████████| 11507/11507 [00:00<00:00, 123103.55it/s]Loading question file...\nPreprocessing data... > to dataframe\nPreprocessing data... > to sparse matrix\n\n9205it [00:00, 718192.05it/s]\n2302it [00:00, 1037422.13it/s]\n11507it [00:00, 788470.50it/s]\n9205it [00:00, 85200.79it/s]\n2302it [00:00, 182075.62it/s]\n11507it [00:00, 104690.65it/s]\n 14%|█▍        | 322/2302 [00:00<00:00, 3219.01it/s]Prepare for recommendations... > find 100 neighbors\n100%|██████████| 2302/2302 [00:00<00:00, 3221.05it/s]\n100%|██████████| 2302/2302 [02:02<00:00, 18.82it/s]\nWriting answers...\nMusic nDCG: 0.112757\nTag nDCG: 0.362646\nScore: 0.150241\n"
    }
   ],
   "source": [
    "# k-neighbor = 100, Similarity Ration = (0.15, 0.85)\n",
    "\n",
    "model = ModelKNNTFIDF()\n",
    "model.run(train_fname='../arena_data/orig/train.json', question_fname='../arena_data/questions/val.json')\n",
    "\n",
    "evaluator = ArenaEvaluator()\n",
    "evaluator.evaluate(gt_fname='../arena_data/answers/val.json', rec_fname='./arena_data/results/results.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Music nDCG: 0.13871\n",
    "Tag nDCG: 0.395219\n",
    "Score: 0.177186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # k-neighbor = 100, Similarity Ration = (0.1, 0.9)\n",
    "\n",
    "# model = ModelKNNTFIDF()\n",
    "# model.run(train_fname='../arena_data/orig/train.json', question_fname='../arena_data/questions/val.json')\n",
    "\n",
    "# evaluator = ArenaEvaluator()\n",
    "# evaluator.evaluate(gt_fname='../arena_data/answers/val.json', rec_fname='./arena_data/results/results.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Music nDCG: 0.13866\n",
    "Tag nDCG: 0.386885\n",
    "Score: 0.175894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # k-neighbor = 100, Similarity Ration = (0.15, 0.85)\n",
    "\n",
    "# playlist_continuation = PlaylistContinuation()\n",
    "# playlist_continuation.run(train_fname='../res/train.json', question_fname='../res/val.json')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitvenvvenv77235a9261d1435da9b22f1d2e41fd2d",
   "display_name": "Python 3.7.4 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}